---
title: "Snap Tool"
author: "Emma Jones"
date: "January 2, 2019"
output: html_document
---

```{r setup, include=FALSE}

# Run in R3.5.1

knitr::opts_chunk$set(echo = TRUE)
#library(dplyr)
#library(readr)
#library(purrr)
library(tidyverse)
library(sf)
```

This script demonstrates an initial workflow to retrieve attribute information from NHD flowlines. All analysis will comply with tidy data workflows. 

### Initial Thoughts on Snapping Points to Lines

**Background** 
I built an S3 version of this workflow in ~2015 to snap VDEQ monitoring locations to a NHD polyline shapefile with embedded Water Quality Standards information. This process was an initial step in automating WQS assessment workflows throughout the state. After a few years of project stagnation, renewed interest in automating assessments came about in 2017 with increased shiny app acceptance within the agency. The goal of this snapping project is to develop a function that can take point information and associate the nearest line feature for extraction of attribute info. 

**Why a new function?** 
After thorough exploration of native sf snapping functions (sf::st_snap, sf::st_nearest_feature) I have determined that they do not fully meet needs for flow line applications. These functions only return the closest feature to an input point, which can mask errors in snapping to the 'correct' flow line. Though a number of lat/lng fall close enough to stream segments to use the above mentioned snapping functions, there are cases where a point falls close to 2+ flow lines. These require manual QA to identify where the point intended to snap to. By only returning the closest feature, these cases are masked from users and can potentially snap to incorrect stream segments. There is value in knowing how many segments are identified within a given buffer distance.

### Snapping Functions that output Points

These nested functions accomplish the task of taking input spreadsheet point data and snapping to nearest line segments. **This version of the functions output point(s) instead of a list of lines and points.** See snapFunctions.Rmd for previous iterations of snapping function.

Bring in test dataset. I clipped a small bit of the WQS layer from New river basin for test NHD. The points are a few real and a few made up (I picked sites that would purposefully grab too many stream geometries) for testing. I made sure to start with a spreadsheet form to make sure the function will be most useful to people. The sf transformation steps can happen in an outer function and can build out something that tests incoming dataset and adjusts workflow accordingly.

```{r newTestData}
WQS <- st_read('data/WQS2018_BRRO_albers_mini.shp')

probSites_xl <- read_csv('data/probSites_mini.csv')

probSites_sf <- st_as_sf(probSites_xl, 
                    coords = c("LongitudeD", "LatitudeDD"), # for point data
                    remove = F, # don't remove these lat/lon cols from df
                    crs = 4269) %>% # add projection, needs to be geographic for now bc entering lat/lng, 
  st_transform( st_crs(WQS))# project to Albers equal area for snapping

# make sure both layers have same CRS
identical(st_crs(WQS),st_crs(probSites_sf))
```


Starting small, build first function that just buffers single site X distance and lets user know if there is a match with input polyline file. Still using my version of inner function because I don't want to test to see if a buffer intersects a stream, then re-grab that stream's unique identifier in a separate step. I think it makes more sense to just do the st_intersect once even though the apply() functionality is a tad faster, I would need to st_intersect twice to get out the info I need.


```{r bufferFunction}
# For testing
POINT <- probSites_sf[1,]
MULTILINESTRING <- WQS
distance <- 40

snap_bufferMethod <- function(POINT, MULTILINESTRING, distance){
  step1 <- st_buffer(POINT,dist = distance)
  st_zm(MULTILINESTRING) %>% 
    filter(st_intersects(., st_zm(step1), sparse = FALSE))
}

snap_bufferMethod(probSites_sf[1,],WQS,5)
snap_bufferMethod(probSites_sf[1,],WQS,40)
```

Then build outer function that accepts sequence of buffer distances for a single site.

```{r buffer series}
# For testing
POINT <- probSites_sf[4,]#probSites_sf[1,]#probSites_sf[5,]#
MULTILINESTRING_UID_colname <- "OBJECTID"
MULTILINESTRING <- WQS
bufferDistances <- seq(10,50,by=10)

snap_Point_to_Feature <- function(POINT, # sf POINT file
                                  MULTILINESTRING, # stream network
                                  MULTILINESTRING_UID_colname, # as.character(name of unique identifier in POINT file)
                                  bufferDistances # numeric sequence of distances to run buffer, these will be in
                                  ){              # the unit of the POINT and MULTILINESTRING files
  
   x <- 0
  repeat {
   x <- x + 1
   b <- snap_bufferMethod(POINT,MULTILINESTRING,bufferDistances[x])
   if (nrow(b) > 0 | x == length(bufferDistances)) break   }
  

  if( nrow(b) == 0 ){
    c <- mutate(POINT, `MULTILINESTRING Unique Identifier` = NA,
                `Buffer Distance` = paste('No connections within', max(bufferDistances),
                                        st_crs(POINT)$units, sep = ' '))
  } else {
       cn <- as.character(st_set_geometry(b,NULL) %>% select_(MULTILINESTRING_UID_colname) %>% flatten_chr())
       c <- POINT %>%
         slice(rep(1:n(), each = length(cn))) %>% # replicate rows of POINT file length(cn) times to mutate cn info
         mutate(`MULTILINESTRING Unique Identifier` = cn,
                   `Buffer Distance` = paste(bufferDistances[x], 
                                             st_crs(POINT)$units, sep = ' ')) }
  return(c)
}

snap_Point_to_Feature(probSites_sf[1,], WQS, 'OBJECTID',  seq(10,50, 5))
``` 

But if you want to make a dataset with sites that did connect to something and sites that didn't it causes problems in MULTILINESTRING object.

```{r problemsIdentified}
z1 <- snap_Point_to_Feature(probSites_sf[1,], WQS, 'OBJECTID', seq(10,50,by=10)) # one connection
z3 <- snap_Point_to_Feature(probSites_sf[4,], WQS, 'OBJECTID', seq(10,50,by=10)) # three connections
z0 <- snap_Point_to_Feature(probSites_sf[5,], WQS, 'OBJECTID', seq(10,50,by=10)) # no connection

z4 <- suppressWarnings(bind_rows(z1,z3,z0) )
z5 <- suppressWarnings(rbind(z1,z3,z0, deparse.level = 1)) 
# clean up workspace
rm(list=setdiff(ls(), c("probSites_sf", "probSites_xl", "snap_bufferMethod", "snap_Point_to_Feature", "WQS")))

```


Now need to extend this to MULTIPOINT features so user can easily use with spreadsheet-like input. This function outputs a multipoint object with all sites that were initially fed to function. Buffer information and the UID of the line segment it attached to within said buffer is included with each point. If no lines are snapped to within a given buffer sequence, then the original point is returned with a comment about maximum buffer attempted without success. If multiple lines are returned within a given buffer for a single point, all lines will be returned with a comment on buffer distance that they fell within. Thus, the number of rows in the sf object returned will be at least the same number as fed into the function.

Update: implement purrr::map() instead of loop to speed processing.

```{r multipoint output}
#MULTIPOINT <- probSites_sf
#POINT_UID_colname <- 'StationID'
#MULTILINESTRING_UID_colname <- "OBJECTID"
#MULTILINESTRING <- WQS
#bufferDistances <- seq(10,50,by=10)


snap_Points_to_Feature <- function(MULTIPOINT, # sf MULTIPOINT file
                                   MULTIPOINT_UID_colname, # as.character(name of unique identifier in POINT file)
                                   MULTILINESTRING, # stream network
                                   MULTILINESTRING_UID_colname, # as.character(name of unique identifier in POINT file)
                                   bufferDistances # numeric sequence of distances to run buffer, these will be in
                                   ){              # the unit of the MULTIPOINT and MULTILINESTRING files)
  # get array of point column name
  MULTIPOINT_UID <- MULTIPOINT[[MULTIPOINT_UID_colname]]
  
  # apply function to all point features
  z <- MULTIPOINT %>%
    split(MULTIPOINT_UID) %>%
    map( ~ snap_Point_to_Feature(.x, WQS, 'OBJECTID', seq(10,50,by=10))) #%>%
  #bind_rows() %>% st_sf() # would like to pipe everything but need to get handsy with data if use bind_rows
  # do.call provides same data structure as input without much effort, so two steps but better end product
  # compared to a single pipe
  
  return(do.call(rbind,z))
}

# clean up workspace, make sure functions really working after testing
rm(list=setdiff(ls(), c("probSites_sf", "probSites_xl", "snap_bufferMethod", "snap_Point_to_Feature", "WQS",
                        "snap_Points_to_Feature")))

z <- snap_Points_to_Feature(probSites_sf, 'StationID', WQS, "OBJECTID", seq(10,50,by=10))

```

Now all user needs to do is:
1) z2 <- filter(z, !is.na(`MULTILINESTRING Unique Identifier`)) to get rid of super problem sites (will need to do hand QA on those sites
2) left_join the z2 output to the original line file to get line segments of interest
3) QA where > 1 line segment per point ... we can build more QA helpers as discussed on phone with string searches?

Those steps could be wrapped into functions, but not sure if necessary? Might show a workflow in a vignette of how to deal with three potential cases and call it a day?
